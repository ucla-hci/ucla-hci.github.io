team:
  - name: Xiang 'Anthony' Chen
    role: Assistant Professor
    expertise: Pirate Investigator
    img: Anthony-s.JPG
    imgalt: Anthony-f.JPG
    affliation: Electrical & Computer Engineering
    email: xac @ ucla.edu
    bio: Xiang ‘Anthony' Chen is an Assistant Professor in UCLA's Department of Electrical & Computer Engineering. Anthony's area of expertise is Human-Computer Interaction (HCI). He received his Ph.D. in the School of Computer Science at Carnegie Mellon University in 2017 and was a recipient of the NSF CISE CRII Award and the Adobe Ph.D. Fellowship. His research is at the intersection of sensing & interaction techniques, intelligent user interfaces, and computational design & fabrication. Anthony’s work has won two best paper awards and one honorable mentioned in top-tier HCI conferences.
    projects: 
      - Fart Gun 1
      - Fart Gun 2
      - Fart Gun 3
      - Fart Gun 4
  - name: Jiahao Li
    role: MAE PhD
    expertise: Mechanical Engineer
    img: Nick-s.JPG
    imgalt: Nick-f.JPG
  - name: Yao Xie
    role: ECE PhD
    expertise: AI Explainer
    img: Yao-s.JPG
    imgalt: Yao-f.JPG
  - name: Hongyan Gu
    role: ECE PhD
    expertise: Deep Learner
    img: Hongyan-s.JPG
    imgalt: Hongyan-f.JPG
  - name: Ruolin Wang
    role: ECE PhD
    expertise: sabotage
    img: Ruolin-s.JPG
    imgalt: Ruolin-f.JPG
  - name: Noyan Evirgen
    role: ECE PhD
    expertise: sabotage
    img: Noyan-s.JPG
    imgalt: Noyan-f.JPG
  - name: Carlo Rebanal
    role: ECE MS
    expertise: sabotage
    img: Carlo-s.JPG
    imgalt: Carlo-f.JPG
  - name: Ximeng Liu
    role: ECE MS
    expertise: sabotage
    img: Simon-s.JPG
    imgalt: Simon-f.JPG
  - name: Amirali Omidfar
    role: ECE MS
    expertise: sabotage
    img: Amir-s.JPG
    imgalt: Amir-f.JPG
  - name: Nicolas Cheng
    role: ECE MS
    expertise: sabotage
    img: Nicky-s.JPG
    imgalt: Nicky-f.JPG
  - name: Jingbin Huang
    role: ECE Undergrad
    expertise: sabotage
    img: Jingbin-s.JPG
    imgalt: Jingbin-f.JPG
  - name: Lauren Hung
    role: Specialists
    expertise: UI/UX Designer
    img: Lauren-s.JPG
    imgalt: Lauren-f.JPG
  - name: Melody Chen
    role: ECE Undergrad
    expertise: sabotage
    img: Melody-s.JPG
    imgalt: Melody-f.JPG 
  - name: Yuki Tang
    role: Visiting student
    expertise: User Research
    img: Yuki-s.JPG
    imgalt: Yuki-f.JPG 
  # - name: Parth Agrawal
  #   role: ECE Undergrad
  #   expertise: sabotage
  #   img: Parth-s.JPG
  #   imgalt: Parth-f.JPG
# collaborators: []
#   - name: Zhi Li
#     role: MAE PhD
#     expertise: sabotage
#     img: Zhi-s.JPG
#     imgalt: Zhi-f.JPG
#   - name: Yunchu Zhang
#     role: MAE PhD
#     expertise: sabotage
#     img: Yunchu-s.JPG
#     imgalt: Yunchu-f.JPG
alumni:
  - name: Ben Wagstaff
    role: ECE Undergrad
    # expertise: sabotage
    img: Ben-s.JPG
    imgalt: Ben-f.JPG
  - name: Joseph Lu
    role: CS Undergrad
    # expertise: sabotage
    img: Joseph-s.JPG
    imgalt: Joseph-f.JPG
projects:
  - name: 'Robiot'
    title: 'Robiot: A Design Tool for Actuating Everyday Object with Automatically Generated 3D Printable Mechanism'
    authors:
      - 'Jiahao Li, UCLA HCI Research'
      - 'Jeeeun Kim, Texas A&M University'
      - "Xiang 'Anthony' Chen, UCLA HCI Research"
    pubs: UIST 2019
    img: t_robiot.jpg
    abstract: Users can now easily communicate information with an Internet of Things; in contrast, there remains a lack of support to automate tasks that involve legacy static objects, e.g. adjusting a desk lamp's angle for optimal brightness, turning on/off a manual faucet when washing dishes, sliding a window to maintain a preferred indoor temperature. Automating these simple physical tasks has the potential to improve people's quality of life, which is particularly important for people with a disability or in situational impairment.<br/><br/>We present Robiot -- a design tool for generating mechanisms that can be attached to, motorized, and actuating legacy static objects to perform simple physical tasks. Users only need to take a short video manipulating an object to demonstrate an intended physical behavior. Robiot then extracts requisite parameters and automatically generates 3D models of the enabling actuation mechanisms by performing a scene and motion analysis of the 2D video in alignment with the object's 3D model. In an hour-long design session, six participants used Robiot to actuate seven everyday objects, imbuing them with the robotic capability to automate various physical tasks.
    videoSite: vimeo
    video: 358553023
    album: '72157710743420892'
    # citation: Ambrosin, M., Hosseini, H., Mandal, K., Conti, M. and Poovendran, R., 2016, October. Despicable me (ter): Anonymous and fine-grained metering data reporting with dishonest meters. In 2016 IEEE conference on communications and network security (CNS) (pp. 163-171). IEEE.
    # bibtex: @inproceedings{ambrosin2016despicable,<br>&nbsp; &nbsp; &nbsp; &nbsp;title={Despicable me (ter): Anonymous and fine-grained metering data reporting with dishonest meters},<br>&nbsp; &nbsp; &nbsp; &nbsp;author={Ambrosin, Moreno and Hosseini, Hossein and Mandal, Kalikinkar and Conti, Mauro and Poovendran, Radha},<br>&nbsp; &nbsp; &nbsp; &nbsp;booktitle={2016 IEEE conference on communications and network security (CNS)},<br>&nbsp; &nbsp; &nbsp; &nbsp;pages={163--171},<br>&nbsp; &nbsp; &nbsp; &nbsp;year={2016},<br>&nbsp; &nbsp; &nbsp; &nbsp;organization={IEEE}<br>}<br>
    paperUrl: '.'
  - name: Minuet
    pubs: SUI 2019
    authors:
      - 'Runchang Kang & Anhong Guo, Carnegie Mellon University'
      - 'Gierard Laput, Apple'
      - 'Yang Li, Google'
      - "Xiang 'Anthony' Chen, UCLA HCI Research"
    img: t_minuet.jpg
    title: 'Minuet: Multimodal Interaction with an Internet of Things'
    abstract: A large number of Internet-of-Things (IoT) devices will soon populate our physical environments. Yet, IoT devices' reliance on mobile applications and voice-only assistants as the primary interface limits their scalability and expressiveness. Building off of the classic 'Put-That-There' system, we contribute an exploration of the design space of voice + gesture interaction with spatially-distributed IoT devices. Our design space decomposes users' IoT commands into two components---selection and interaction. We articulate how the permutations of voice and freehand gesture for these two components can complementarily afford interaction possibilities that go beyond current approaches. We instantiate this design space as a proof-of-concept sensing platform and demonstrate a series of novel IoT interaction scenarios, such as making 'dumb' objects smart, commanding robotic appliances, and resolving ambiguous pointing at cluttered devices.
    videoSite: vimeo
    video: 358550776
    album: '72157710744632177'
  - name: Fart Gun 3
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 4
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 5
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 6
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 7
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 8
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 9
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 10
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 11
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 12
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 13
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 14
    pubs: MinionCon 2019
    img: fart_gun.jpeg
  - name: Fart Gun 15
    pubs: MinionCon 2019
    img: fart_gun.jpeg
aboutus:
  - mission: "We believe the ultimate goal of inventing the computer is to augment our human selves. To achieve this, my group's research focuses on the following three topics:<br><ul><li><b>Intelligent User Interfaces</b>: how can we design interfaces of intelligent systems that augment a user to accomplish domain-specific tasks?</li><li><b>Sensing & Interaction Techniques</b>: how can we invent new sensors and devices that afford novel experiences for users to interact with a computer?</li><li><b>Computational Design & Fabrication</b>how can we build computational platforms that empower users to realize their ideas into digital or physical artifacts?</li></ul>"
    photos: 
      - g_bbq.jpg
      - g_collaboration.JPG
      - g_dogders.JPG
      - g_dinner.jpg
      # - minions1.jpg
      # - minions8.jpg
      # - minions3.jpg
      # - minions4.jpg
      # - minions5.jpg
      # - minions6.jpg
      # - minions7.jpg
      # - minions2.png
    contact:
      description: UCLA HCI Research is part of the Electrical & Computer Engineering Department in the Henry Samueli School of Engineering at UCLA.
      address: <b>UCLA HCI Research</b><br/>1538 Boelter Hall, UCLA<br/>Los Angeles, CA 90095
      email: Email: sigchi @ ucla.edu
    sponsors:
      - img: nsf.png
        url: https://nsf.gov/
      - img: adobe.png
        url: https://www.adobe.com/
      - img: meta.png
        url: https://www.metachnology.com/
    map: <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d1991.4035161501527!2d-118.44520705236775!3d34.06920012829791!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x80c2bc8632b4bcf3%3A0x8087319fe00f1e04!2sUCLA+HCI+Research!5e0!3m2!1sen!2sus!4v1555280319576!5m2!1sen!2sus" width="500" height="400" frameborder="0" style="border:0" allowfullscreen></iframe>
  